{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "blank-nylon",
   "metadata": {},
   "source": [
    "# Fitting a Logistic Regression Model on a High-Dimensional Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mounted-asian",
   "metadata": {},
   "source": [
    "<b> Implement all steps from Exercise 14.01 until the normalization of data. Derive the transformed independent X_tran variable </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "brown-polls",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "committed-poland",
   "metadata": {},
   "outputs": [],
   "source": [
    "url_path = 'https://raw.githubusercontent.com/PacktWorkshops/The-Data-Science-Workshop/master/Chapter14/Dataset/ad.data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "relative-method",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>1549</th>\n",
       "      <th>1550</th>\n",
       "      <th>1551</th>\n",
       "      <th>1552</th>\n",
       "      <th>1553</th>\n",
       "      <th>1554</th>\n",
       "      <th>1555</th>\n",
       "      <th>1556</th>\n",
       "      <th>1557</th>\n",
       "      <th>1558</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>125</td>\n",
       "      <td>125</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>ad.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>57</td>\n",
       "      <td>468</td>\n",
       "      <td>8.2105</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>ad.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33</td>\n",
       "      <td>230</td>\n",
       "      <td>6.9696</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>ad.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>60</td>\n",
       "      <td>468</td>\n",
       "      <td>7.8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>ad.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60</td>\n",
       "      <td>468</td>\n",
       "      <td>7.8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>ad.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 1559 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0     1       2    3     4     5     6     7     8     9     ...  1549  \\\n",
       "0   125   125     1.0    1     0     0     0     0     0     0  ...     0   \n",
       "1    57   468  8.2105    1     0     0     0     0     0     0  ...     0   \n",
       "2    33   230  6.9696    1     0     0     0     0     0     0  ...     0   \n",
       "3    60   468     7.8    1     0     0     0     0     0     0  ...     0   \n",
       "4    60   468     7.8    1     0     0     0     0     0     0  ...     0   \n",
       "\n",
       "   1550  1551  1552  1553  1554  1555  1556  1557  1558  \n",
       "0     0     0     0     0     0     0     0     0   ad.  \n",
       "1     0     0     0     0     0     0     0     0   ad.  \n",
       "2     0     0     0     0     0     0     0     0   ad.  \n",
       "3     0     0     0     0     0     0     0     0   ad.  \n",
       "4     0     0     0     0     0     0     0     0   ad.  \n",
       "\n",
       "[5 rows x 1559 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adData = pd.read_csv(url_path, header=None, error_bad_lines=False)\n",
    "adData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "distributed-belly",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = adData.loc[:, 0:1557]\n",
    "Y = adData[1558]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "terminal-mystery",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3279, 1558)\n",
      "(3279,)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "every-share",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,3):\n",
    "    X[i] = X[i].str.replace(\"?\", 'NaN').values.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "presidential-instrumentation",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(3,1557):\n",
    "    X[i] = X[i].replace(\"?\", 'NaN').values.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "presidential-extension",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,1557):\n",
    "    X[i] = X[i].fillna(X[i].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "featured-retrieval",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "X_tran = pd.DataFrame(scaler.fit_transform(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "based-brazil",
   "metadata": {},
   "source": [
    "<b> Create a high-dimensional dataset by replicating the columns 80 times using the pd.np.tile() function. Print the shape of the new dataset and observe the number of features in the new dataset </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "closed-lafayette",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3279, 155800)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_hd = pd.DataFrame(pd.np.tile(X_tran, (1, 80)))\n",
    "X_hd.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incorrect-battlefield",
   "metadata": {},
   "source": [
    "<b> Split the dataset into train and test sets </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "capital-david",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_hd, Y, test_size=0.3, random_state=123)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "previous-january",
   "metadata": {},
   "source": [
    "<b> Fit a logistic regression model on the new dataset and note the time it takes to fit the model </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "common-worthy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 24s\n",
      "Parser   : 270 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "engaged-anger",
   "metadata": {},
   "source": [
    "<b> Predict on the test set and print the classification report and confusion matrix </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "mobile-venue",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "unable-galaxy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on Logistic Regression model prediction on test set: 0.9715447154471545\n"
     ]
    }
   ],
   "source": [
    "print(f'Accuracy on Logistic Regression model prediction on test set: {model.score(X_test, y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "congressional-design",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[110  16]\n",
      " [ 12 846]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "vital-respect",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ad.       0.90      0.87      0.89       126\n",
      "      nonad.       0.98      0.99      0.98       858\n",
      "\n",
      "    accuracy                           0.97       984\n",
      "   macro avg       0.94      0.93      0.94       984\n",
      "weighted avg       0.97      0.97      0.97       984\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "multiple-honolulu",
   "metadata": {},
   "source": [
    "# Comparison of Dimensionality Reduction Techniques on the Enhanced Ads Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adopted-musical",
   "metadata": {},
   "source": [
    "<b> Create a high-dimensional dataset by replicating the columns twice </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "modular-cookbook",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3279, 3116)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_hd = pd.DataFrame(pd.np.tile(X_tran, (1, 2)))\n",
    "X_hd.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "going-trout",
   "metadata": {},
   "source": [
    "<b> Create random samples from a normal distribution with mean = 0 and standard deviation = 0.1. Make the new dataset with the same shape as the high-dimensional dataset </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "opposed-syntax",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining mean and standard deviation\n",
    "mu = 0\n",
    "sigma = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "eleven-portuguese",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3279, 3116)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate samples from the normal distribution\n",
    "noise = np.random.normal(mu, sigma, [3279, 3116])\n",
    "noise.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "integral-finland",
   "metadata": {},
   "source": [
    "<b> Add the high dimensional dataset and the random samples to get the new dataset </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "narrative-microwave",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new = X_hd + noise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "controlled-links",
   "metadata": {},
   "source": [
    "<b> Split the dataset into train and test sets </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "intended-explosion",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_new, Y, test_size=0.3, random_state=123)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acknowledged-opportunity",
   "metadata": {},
   "source": [
    "<b> Implement backward elimination </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "innovative-democrat",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "sorted-register",
   "metadata": {},
   "outputs": [],
   "source": [
    "backModel = LogisticRegression()\n",
    "rfe = RFE(backModel, 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "subjective-emperor",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RFE(estimator=LogisticRegression(), n_features_to_select=300)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "neutral-housing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   1,   12,   14,   35,   53,   64,   73,   75,   88,   95,   98,\n",
       "         99,  119,  130,  134,  141,  158,  163,  166,  167,  172,  246,\n",
       "        251,  262,  271,  278,  284,  307,  317,  322,  338,  341,  351,\n",
       "        356,  365,  372,  380,  398,  402,  418,  424,  441,  457,  499,\n",
       "        508,  515,  541,  543,  556,  562,  593,  610,  638,  658,  679,\n",
       "        680,  686,  692,  698,  705,  709,  715,  717,  719,  721,  726,\n",
       "        731,  736,  737,  766,  769,  785,  803,  813,  815,  831,  840,\n",
       "        850,  860,  863,  865,  866,  874,  887,  910,  917,  937,  950,\n",
       "        968,  982,  983,  988,  999, 1000, 1002, 1004, 1021, 1023, 1034,\n",
       "       1035, 1043, 1060, 1081, 1106, 1107, 1111, 1134, 1146, 1147, 1167,\n",
       "       1184, 1196, 1202, 1203, 1210, 1229, 1243, 1247, 1249, 1256, 1271,\n",
       "       1276, 1288, 1292, 1306, 1309, 1310, 1326, 1327, 1339, 1344, 1346,\n",
       "       1351, 1357, 1359, 1380, 1385, 1388, 1399, 1403, 1409, 1417, 1424,\n",
       "       1434, 1437, 1445, 1454, 1465, 1471, 1478, 1484, 1492, 1493, 1504,\n",
       "       1518, 1527, 1531, 1532, 1534, 1552, 1559, 1591, 1607, 1662, 1678,\n",
       "       1684, 1697, 1709, 1719, 1725, 1726, 1732, 1733, 1739, 1740, 1741,\n",
       "       1747, 1757, 1776, 1802, 1804, 1823, 1827, 1850, 1865, 1869, 1886,\n",
       "       1889, 1894, 1904, 1909, 1915, 1924, 1926, 1947, 1956, 1964, 1975,\n",
       "       1976, 1978, 1984, 1992, 1993, 2001, 2002, 2009, 2013, 2015, 2019,\n",
       "       2028, 2060, 2066, 2095, 2107, 2114, 2132, 2147, 2150, 2167, 2182,\n",
       "       2192, 2206, 2211, 2216, 2219, 2221, 2281, 2308, 2346, 2370, 2377,\n",
       "       2378, 2379, 2388, 2404, 2409, 2439, 2464, 2477, 2484, 2498, 2501,\n",
       "       2523, 2526, 2538, 2541, 2545, 2555, 2571, 2573, 2576, 2580, 2593,\n",
       "       2594, 2609, 2616, 2618, 2658, 2674, 2697, 2706, 2732, 2750, 2751,\n",
       "       2760, 2782, 2787, 2801, 2812, 2813, 2814, 2834, 2836, 2841, 2844,\n",
       "       2882, 2898, 2899, 2924, 2925, 2932, 2938, 2945, 2957, 2971, 2976,\n",
       "       2983, 2985, 3003, 3012, 3013, 3016, 3020, 3041, 3053, 3065, 3094,\n",
       "       3097, 3104, 3113], dtype=int64)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfe.get_support(indices=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fifth-remainder",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_trans = rfe.transform(X_train)\n",
    "X_test_trans = rfe.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "alike-facing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RfeModel = LogisticRegression()\n",
    "RfeModel.fit(X_train_trans, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "characteristic-marijuana",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make prediction\n",
    "pred = RfeModel.predict(X_test_trans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "minimal-christian",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Logistic Regression model: 0.9644308943089431\n"
     ]
    }
   ],
   "source": [
    "# calculate the accuracy's model\n",
    "print(f'Accuracy of Logistic Regression model: {RfeModel.score(X_test_trans, y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "varied-testimony",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 95  31]\n",
      " [  4 854]]\n"
     ]
    }
   ],
   "source": [
    "# confusion matrix\n",
    "print(confusion_matrix(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "demanding-turner",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ad.       0.96      0.75      0.84       126\n",
      "      nonad.       0.96      1.00      0.98       858\n",
      "\n",
      "    accuracy                           0.96       984\n",
      "   macro avg       0.96      0.87      0.91       984\n",
      "weighted avg       0.96      0.96      0.96       984\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# classification report\n",
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abandoned-cradle",
   "metadata": {},
   "source": [
    "<b> Implement the forward selection technique </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "planned-setting",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "speaking-rates",
   "metadata": {},
   "outputs": [],
   "source": [
    "feats = SelectKBest(k=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "neural-regular",
   "metadata": {},
   "outputs": [],
   "source": [
    "fit = feats.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "invisible-planner",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train = fit.transform(X_train)\n",
    "features_test = fit.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "helpful-helena",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forwardModel = LogisticRegression()\n",
    "forwardModel.fit(features_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "mighty-footwear",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions\n",
    "pred = forwardModel.predict(features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "upper-communist",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the Logistic Regression model: 0.9623983739837398\n"
     ]
    }
   ],
   "source": [
    "# accuracy's model\n",
    "print(f'Accuracy of the Logistic Regression model: {forwardModel.score(features_test, y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "former-weapon",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 90  36]\n",
      " [  1 857]]\n"
     ]
    }
   ],
   "source": [
    "# confusion matrix\n",
    "print(confusion_matrix(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "statistical-shopper",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ad.       0.99      0.71      0.83       126\n",
      "      nonad.       0.96      1.00      0.98       858\n",
      "\n",
      "    accuracy                           0.96       984\n",
      "   macro avg       0.97      0.86      0.90       984\n",
      "weighted avg       0.96      0.96      0.96       984\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# classification report\n",
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "organizational-springer",
   "metadata": {},
   "source": [
    "<b> Implement PCA </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "owned-street",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "affected-crash",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "portuguese-trinidad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(pca.explained_variance_ratio_)\n",
    "plt.xlabel('Number of Principal Components')\n",
    "plt.ylabel('Cumulative explained variance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "enormous-hartford",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=300).fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "virtual-spider",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_pca = pca.transform(X_train)\n",
    "X_test_pca = pca.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "overall-rhythm",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pcaModel = LogisticRegression()\n",
    "pcaModel.fit(X_train_pca, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "after-yukon",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = pcaModel.predict(X_test_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "defined-liberal",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the Logistic Regression model: 0.9684959349593496\n"
     ]
    }
   ],
   "source": [
    "# accuracy's model\n",
    "print(f'Accuracy of the Logistic Regression model: {pcaModel.score(X_test_pca, y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "wicked-italian",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 97  29]\n",
      " [  2 856]]\n"
     ]
    }
   ],
   "source": [
    "# confusion matrix\n",
    "print(confusion_matrix(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "blond-television",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ad.       0.98      0.77      0.86       126\n",
      "      nonad.       0.97      1.00      0.98       858\n",
      "\n",
      "    accuracy                           0.97       984\n",
      "   macro avg       0.97      0.88      0.92       984\n",
      "weighted avg       0.97      0.97      0.97       984\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# classification report\n",
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "touched-quantity",
   "metadata": {},
   "source": [
    "<b> Implement ICA </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "experienced-consensus",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import FastICA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "labeled-picking",
   "metadata": {},
   "outputs": [],
   "source": [
    "ICA = FastICA(n_components=300, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "complimentary-strip",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_ica = ICA.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "future-cassette",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_ica = ICA.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "related-flood",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "icaModel = LogisticRegression()\n",
    "icaModel.fit(X_train_ica, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "treated-serum",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = icaModel.predict(X_test_ica)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "joint-quantum",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the Logistic Regression model: 0.8719512195121951\n"
     ]
    }
   ],
   "source": [
    "# accuracy's model\n",
    "print(f'Accuracy of the Logistic Regression model: {icaModel.score(X_test_ica, y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "narrow-backing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0 126]\n",
      " [  0 858]]\n"
     ]
    }
   ],
   "source": [
    "# confusion matrix\n",
    "print(confusion_matrix(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "american-exhaust",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ad.       0.00      0.00      0.00       126\n",
      "      nonad.       0.87      1.00      0.93       858\n",
      "\n",
      "    accuracy                           0.87       984\n",
      "   macro avg       0.44      0.50      0.47       984\n",
      "weighted avg       0.76      0.87      0.81       984\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# classification report\n",
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "signal-origin",
   "metadata": {},
   "source": [
    "<b> Implement factor analysis </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "another-butter",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import FactorAnalysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "lonely-simulation",
   "metadata": {},
   "outputs": [],
   "source": [
    "fa = FactorAnalysis(n_components=30, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "verbal-newsletter",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_fa = fa.fit_transform(X_train)\n",
    "X_test_fa = fa.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "sharing-constitution",
   "metadata": {},
   "outputs": [],
   "source": [
    "faModel = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "representative-projection",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "faModel.fit(X_train_fa, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "correct-aviation",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = faModel.predict(X_test_fa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "based-meaning",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the Logistic Regression model: 0.959349593495935\n"
     ]
    }
   ],
   "source": [
    "# accuracy's model\n",
    "print(f'Accuracy of the Logistic Regression model: {faModel.score(X_test_fa, y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "natural-encounter",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 86  40]\n",
      " [  0 858]]\n"
     ]
    }
   ],
   "source": [
    "# confusion matrix\n",
    "print(confusion_matrix(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "bridal-diary",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ad.       1.00      0.68      0.81       126\n",
      "      nonad.       0.96      1.00      0.98       858\n",
      "\n",
      "    accuracy                           0.96       984\n",
      "   macro avg       0.98      0.84      0.89       984\n",
      "weighted avg       0.96      0.96      0.96       984\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# classification report\n",
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "enhanced-cuisine",
   "metadata": {},
   "source": [
    "<b> Compare the outputs of all the methods </b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tested-sacramento",
   "metadata": {},
   "source": [
    "We can see that three methods (backward elimination, forward selection, and PCA) have got the same accuracy scores. Therefore, the selection criteria for the best method should be based on the time taken to get the reduced dimension.\n",
    "\n",
    "We should strike a balance between accuracy and the time taken for dimensionality reduction. We can see that factor analysis and backward elimination have very close accuracy scores, 96% and 97% respectively."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
