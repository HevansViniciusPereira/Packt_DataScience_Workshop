{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "hundred-ideal",
   "metadata": {},
   "source": [
    "# Building a Classification Model with Features that have been Generated Using Featuretools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "quick-brain",
   "metadata": {},
   "source": [
    "<b> Read the data </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "persistent-german",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eastern-concord",
   "metadata": {},
   "outputs": [],
   "source": [
    "url_path = 'https://raw.githubusercontent.com/PacktWorkshops/The-Data-Science-Workshop/master/Chapter17/Datasets/adult.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "located-lloyd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours</th>\n",
       "      <th>native</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>77516</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>83311</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>215646</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>234721</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>338409</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age          workclass  fnlwgt   education  education-num  \\\n",
       "0   39          State-gov   77516   Bachelors             13   \n",
       "1   50   Self-emp-not-inc   83311   Bachelors             13   \n",
       "2   38            Private  215646     HS-grad              9   \n",
       "3   53            Private  234721        11th              7   \n",
       "4   28            Private  338409   Bachelors             13   \n",
       "\n",
       "        marital-status          occupation    relationship      sex  \\\n",
       "0        Never-married        Adm-clerical   Not-in-family     Male   \n",
       "1   Married-civ-spouse     Exec-managerial         Husband     Male   \n",
       "2             Divorced   Handlers-cleaners   Not-in-family     Male   \n",
       "3   Married-civ-spouse   Handlers-cleaners         Husband     Male   \n",
       "4   Married-civ-spouse      Prof-specialty            Wife   Female   \n",
       "\n",
       "   capital-gain  capital-loss  hours          native  label  \n",
       "0          2174             0     40   United-States      0  \n",
       "1             0             0     13   United-States      0  \n",
       "2             0             0     40   United-States      0  \n",
       "3             0             0     40   United-States      0  \n",
       "4             0             0     40            Cuba      0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(url_path, na_values='?')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "nuclear-funeral",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32561, 14)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hearing-turkish",
   "metadata": {},
   "source": [
    "<b> Drop all na values </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "changing-egypt",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age               0\n",
       "workclass         0\n",
       "fnlwgt            0\n",
       "education         0\n",
       "education-num     0\n",
       "marital-status    0\n",
       "occupation        0\n",
       "relationship      0\n",
       "sex               0\n",
       "capital-gain      0\n",
       "capital-loss      0\n",
       "hours             0\n",
       "native            0\n",
       "label             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "healthy-confirmation",
   "metadata": {},
   "source": [
    "There is no na value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hearing-fireplace",
   "metadata": {},
   "source": [
    "<b> Create the Y variable </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "illegal-huntington",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = df.pop('label')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wanted-anthony",
   "metadata": {},
   "source": [
    "<b> Split the dataset into train and test sets </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "hungarian-conditions",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "liable-producer",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df, Y, test_size=0.3, random_state=123)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "novel-interaction",
   "metadata": {},
   "source": [
    "<b> Create the processor pipeline to convert categorical variables into one-hot encoding and numerical variables into scaled variables </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "critical-worry",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "minute-magnitude",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_transformer = Pipeline(steps=[('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "num_transformer = Pipeline(steps=[('scaler', StandardScaler())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "enormous-exception",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = df.select_dtypes(include=['int64', 'float64']).columns\n",
    "cat_features = df.select_dtypes(include=['object']).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "historical-planning",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "preprocessor = ColumnTransformer(transformers=[('num', num_transformer, num_features),\n",
    "                                              ('cat', cat_transformer, cat_features)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "willing-sandwich",
   "metadata": {},
   "source": [
    "<b> Define the estimator function using the data processor and a logistic regression classifier </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "powerful-recovery",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "sonic-failure",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                           ('classifier', LogisticRegression(random_state=123))])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fluid-whole",
   "metadata": {},
   "source": [
    "<b> Fit the estimator on the train set and then print the scores on the test set </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "retained-division",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hevans\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('preprocessor',\n",
       "                 ColumnTransformer(transformers=[('num',\n",
       "                                                  Pipeline(steps=[('scaler',\n",
       "                                                                   StandardScaler())]),\n",
       "                                                  Index(['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss',\n",
       "       'hours'],\n",
       "      dtype='object')),\n",
       "                                                 ('cat',\n",
       "                                                  Pipeline(steps=[('onehot',\n",
       "                                                                   OneHotEncoder(handle_unknown='ignore'))]),\n",
       "                                                  Index(['workclass', 'education', 'marital-status', 'occupation',\n",
       "       'relationship', 'sex', 'native'],\n",
       "      dtype='object'))])),\n",
       "                ('classifier', LogisticRegression(random_state=123))])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cognitive-newfoundland",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model score: 0.8530044016787798\n"
     ]
    }
   ],
   "source": [
    "print(f'Model score: {estimator.score(X_test, y_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "forty-assault",
   "metadata": {},
   "source": [
    "<b> Generate predictions on the test set </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "standard-testament",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = estimator.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "introductory-julian",
   "metadata": {},
   "source": [
    "<b> Print the classification report </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "endless-shakespeare",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "expressed-democrat",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.94      0.91      7408\n",
      "           1       0.75      0.59      0.66      2361\n",
      "\n",
      "    accuracy                           0.85      9769\n",
      "   macro avg       0.81      0.76      0.78      9769\n",
      "weighted avg       0.85      0.85      0.85      9769\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ideal-nudist",
   "metadata": {},
   "source": [
    "From the preceding output, we can see that the benchmark model has an accuracy of 85%. We would also be interested in the recall values of the different classes. Class 0 has a recall value of 88%, which means that out of 7189 adults who did not earn an income of more than 50,000 per year, 88% were correctly identified. Class 1 has a recall value of 75%, which indicates that 75% of adults who earned more than 50,000 per year were correctly identified."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "capable-passport",
   "metadata": {},
   "source": [
    "<b> Create a parent entity ID called parentID </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "recovered-adrian",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['parentID'] = df.index.values\n",
    "df['parentID'] = 'record' + df['parentID'].astype('str')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "transparent-repository",
   "metadata": {},
   "source": [
    "<b> For the workclass variable, the unique values are as follows: ' Federal-gov', ' Local-gov', ' Private',' Self-emp-inc', ' Self-emp-not-inc', ' State-gov', ' Without-pay' </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "seventh-favorite",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df.workclass == ' Federal-gov','workId'] = 1\n",
    "df.loc[df.workclass == ' Local-gov','workId'] = 2\n",
    "df.loc[df.workclass == ' Private','workId'] = 3\n",
    "df.loc[df.workclass == ' Self-emp-inc','workId'] = 4\n",
    "df.loc[df.workclass == ' Self-emp-not-inc','workId'] = 5\n",
    "df.loc[df.workclass == ' State-gov','workId'] = 6\n",
    "df.loc[df.workclass == ' Without-pay','workId'] = 7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "great-singing",
   "metadata": {},
   "source": [
    "<b> For the Occupation variable, the unique values are as follows:' Adm-clerical', ' Armed-Forces',' Craft-repair', ' Exec-managerial', ' Farming-fishing',' Handlers-cleaners', ' Machine-op-inspct', ' Other-service', ' Priv-house-serv', ' Prof-specialty',' Protective-serv',' Sales', ' Tech-support', ' Transport-moving' </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "broadband-solid",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df.occupation == ' Adm-clerical','occuId']= 1\n",
    "df.loc[df.occupation == ' Armed-Forces','occuId']= 2\n",
    "df.loc[df.occupation == ' Craft-repair','occuId']= 3\n",
    "df.loc[df.occupation == ' Exec-managerial','occuId']= 4\n",
    "df.loc[df.occupation == ' Farming-fishing','occuId']= 5\n",
    "df.loc[df.occupation == ' Handlers-cleaners','occuId']= 6\n",
    "df.loc[df.occupation == ' Machine-op-inspct','occuId']= 7\n",
    "df.loc[df.occupation == ' Other-service','occuId']= 8\n",
    "df.loc[df.occupation == ' Priv-house-serv','occuId']= 9\n",
    "df.loc[df.occupation == ' Prof-specialty','occuId']= 10\n",
    "df.loc[df.occupation == ' Protective-serv','occuId']= 11\n",
    "df.loc[df.occupation == ' Sales','occuId']= 12\n",
    "df.loc[df.occupation == ' Tech-support','occuId']= 13\n",
    "df.loc[df.occupation == ' Transport-moving','occuId']= 14"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "atmospheric-bride",
   "metadata": {},
   "source": [
    "<b> Create the parent entity and set the relationship with education, workclass, and occupation using their respective IDs </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dated-shepherd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import featuretools as ft\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "naval-difference",
   "metadata": {},
   "outputs": [],
   "source": [
    "adultentities = ft.EntitySet(id = 'Adult')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "individual-starter",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Entityset: Adult\n",
       "  Entities:\n",
       "    Parent Data [Rows: 32561, Columns: 16]\n",
       "  Relationships:\n",
       "    No relationships"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adultentities.entity_from_dataframe(entity_id = 'Parent Data',\n",
    "                                    dataframe = df,\n",
    "                                    index = 'parentID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dutch-relative",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Entityset: Adult\n",
       "  Entities:\n",
       "    Parent Data [Rows: 32561, Columns: 13]\n",
       "    education [Rows: 16, Columns: 2]\n",
       "    Workclass [Rows: 8, Columns: 2]\n",
       "    Occupation [Rows: 15, Columns: 2]\n",
       "  Relationships:\n",
       "    Parent Data.education-num -> education.education-num\n",
       "    Parent Data.workId -> Workclass.workId\n",
       "    Parent Data.occuId -> Occupation.occuId"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adultentities.normalize_entity(base_entity_id='Parent Data',\n",
    "                               new_entity_id='education',\n",
    "                               index = 'education-num',\n",
    "                               additional_variables = ['education'])\n",
    "\n",
    "adultentities.normalize_entity(base_entity_id='Parent Data',\n",
    "                               new_entity_id='Workclass',\n",
    "                               index = 'workId',\n",
    "                               additional_variables = ['workclass'])\n",
    "\n",
    "adultentities.normalize_entity(base_entity_id='Parent Data',\n",
    "                               new_entity_id='Occupation',\n",
    "                               index = 'occuId',\n",
    "                               additional_variables = ['occupation'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "technical-concept",
   "metadata": {},
   "source": [
    "<b> Create the aggregation and transformation primitives </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "domestic-acrylic",
   "metadata": {},
   "outputs": [],
   "source": [
    "aggPrimitives = ['std', 'min', 'max', 'mean', 'last', 'count']\n",
    "tranPrimitives=['percentile', 'subtract', 'divide']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "annoying-forum",
   "metadata": {},
   "source": [
    "<b> Create the DFS with the defined primitives </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "educational-aircraft",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Built 114 features\n",
      "Elapsed: 00:01 | Progress: 100%|███████████████████████████████████████████████████████████████████████████████████████\n"
     ]
    }
   ],
   "source": [
    "feature_set, feature_names = ft.dfs(entityset=adultentities,\n",
    "                                    target_entity = 'Parent Data',\n",
    "                                    agg_primitives=aggPrimitives,\n",
    "                                    #trans_primitives=tranPrimitives,\n",
    "                                    max_depth = 2,\n",
    "                                    verbose = 1,\n",
    "                                    n_jobs = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "presidential-findings",
   "metadata": {},
   "source": [
    "<b> Reindex the created data frame </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "superior-messaging",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_set = feature_set.reindex(index=df['parentID'])\n",
    "feature_set = feature_set.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "crude-julian",
   "metadata": {},
   "source": [
    "<b> Drop all the variables related to the IDs </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "touched-ranking",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = feature_set[feature_set.columns[~feature_set.columns.str.contains('parentID|education-num|workId|occuId')]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "becoming-absence",
   "metadata": {},
   "source": [
    "<b> Replace all the infinity values with na and the drop columns </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "declared-probability",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.replace([np.inf, -np.inf], np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "vulnerable-catch",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.dropna(axis=1, how='any')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "surgical-homework",
   "metadata": {},
   "source": [
    "<b> Split the dataset into train and test sets </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "interpreted-shareware",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.3, random_state=123)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dental-pierre",
   "metadata": {},
   "source": [
    "<b> Create the processing pipeline </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "front-resource",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_transformer = Pipeline(steps=[('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "numeric_transformer = Pipeline(steps=[('scaler', StandardScaler())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "humanitarian-treasure",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_features = X.select_dtypes(include=['int64', 'float64']).columns\n",
    "categorical_features = X.select_dtypes(include=['object']).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "interesting-premiere",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "complicated-particular",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = ColumnTransformer(transformers=[('num', numeric_transformer, numeric_features),\n",
    "                                               ('cat', categorical_transformer, categorical_features)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unlimited-wyoming",
   "metadata": {},
   "source": [
    "<b> Create the estimator function and fit the training set on the estimator. Then, generate the scores </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "southwest-northwest",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                            ('classifier', LogisticRegression(random_state=123))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "macro-burner",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hevans\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('preprocessor',\n",
       "                 ColumnTransformer(transformers=[('num',\n",
       "                                                  Pipeline(steps=[('scaler',\n",
       "                                                                   StandardScaler())]),\n",
       "                                                  Index(['age', 'fnlwgt', 'capital-gain', 'capital-loss', 'hours',\n",
       "       'education.COUNT(Parent Data)', 'education.LAST(Parent Data.age)',\n",
       "       'education.LAST(Parent Data.capital-gain)',\n",
       "       'education.LAST(Parent Data.capital-loss)',\n",
       "       'education.LAST(Parent Data...\n",
       "                                                  Pipeline(steps=[('onehot',\n",
       "                                                                   OneHotEncoder(handle_unknown='ignore'))]),\n",
       "                                                  Index(['marital-status', 'relationship', 'sex', 'native',\n",
       "       'education.education', 'education.LAST(Parent Data.marital-status)',\n",
       "       'education.LAST(Parent Data.native)',\n",
       "       'education.LAST(Parent Data.relationship)',\n",
       "       'education.LAST(Parent Data.sex)'],\n",
       "      dtype='object'))])),\n",
       "                ('classifier', LogisticRegression(random_state=123))])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "historical-marble",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model score: 0.8469648889343843\n"
     ]
    }
   ],
   "source": [
    "print(f'Model score: {estimator.score(X_test, y_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "thrown-paper",
   "metadata": {},
   "source": [
    "<b> Generate predictions on the test set and print the classification report </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "intellectual-southwest",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = estimator.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "creative-faith",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.94      0.90      7408\n",
      "           1       0.74      0.56      0.64      2361\n",
      "\n",
      "    accuracy                           0.85      9769\n",
      "   macro avg       0.81      0.75      0.77      9769\n",
      "weighted avg       0.84      0.85      0.84      9769\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hawaiian-nature",
   "metadata": {},
   "source": [
    "From the preceding output, we can see that the accuracy scores have improved from 85% to 86%. There is also an improvement in the precision, recall, and f1-score of the minority class (yes). All of these values have increased from 62%, 75%, and 68% to 64%, 76%, and 69%, respectively. From a business perspective, the result indicates that out of the total 9,049 adults, 86% of them have been correctly identified as earning more than 50,000 per year or not."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
