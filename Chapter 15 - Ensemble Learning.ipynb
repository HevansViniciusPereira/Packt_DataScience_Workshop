{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "chemical-champagne",
   "metadata": {},
   "source": [
    "# Loading, Exploring, and Cleaning the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "varying-trinidad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "immune-pipeline",
   "metadata": {},
   "outputs": [],
   "source": [
    "# url path\n",
    "url_path = 'https://raw.githubusercontent.com/PacktWorkshops/The-Data-Science-Workshop/master/Chapter15/Dataset/crx.data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "extra-relation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b</td>\n",
       "      <td>30.83</td>\n",
       "      <td>0.000</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>w</td>\n",
       "      <td>v</td>\n",
       "      <td>1.25</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>1</td>\n",
       "      <td>f</td>\n",
       "      <td>g</td>\n",
       "      <td>202.0</td>\n",
       "      <td>0</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a</td>\n",
       "      <td>58.67</td>\n",
       "      <td>4.460</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>q</td>\n",
       "      <td>h</td>\n",
       "      <td>3.04</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>6</td>\n",
       "      <td>f</td>\n",
       "      <td>g</td>\n",
       "      <td>43.0</td>\n",
       "      <td>560</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a</td>\n",
       "      <td>24.50</td>\n",
       "      <td>0.500</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>q</td>\n",
       "      <td>h</td>\n",
       "      <td>1.50</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>0</td>\n",
       "      <td>f</td>\n",
       "      <td>g</td>\n",
       "      <td>280.0</td>\n",
       "      <td>824</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b</td>\n",
       "      <td>27.83</td>\n",
       "      <td>1.540</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>w</td>\n",
       "      <td>v</td>\n",
       "      <td>3.75</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>5</td>\n",
       "      <td>t</td>\n",
       "      <td>g</td>\n",
       "      <td>100.0</td>\n",
       "      <td>3</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b</td>\n",
       "      <td>20.17</td>\n",
       "      <td>5.625</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>w</td>\n",
       "      <td>v</td>\n",
       "      <td>1.71</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>0</td>\n",
       "      <td>f</td>\n",
       "      <td>s</td>\n",
       "      <td>120.0</td>\n",
       "      <td>0</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  0      1      2  3  4  5  6     7  8  9   10 11 12     13   14 15\n",
       "0  b  30.83  0.000  u  g  w  v  1.25  t  t   1  f  g  202.0    0  +\n",
       "1  a  58.67  4.460  u  g  q  h  3.04  t  t   6  f  g   43.0  560  +\n",
       "2  a  24.50  0.500  u  g  q  h  1.50  t  f   0  f  g  280.0  824  +\n",
       "3  b  27.83  1.540  u  g  w  v  3.75  t  t   5  t  g  100.0    3  +\n",
       "4  b  20.17  5.625  u  g  w  v  1.71  t  f   0  f  s  120.0    0  +"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the data\n",
    "credData = pd.read_csv(url_path, header=None, na_values='?')\n",
    "credData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "psychological-killing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b</td>\n",
       "      <td>30.83</td>\n",
       "      <td>0.000</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>w</td>\n",
       "      <td>v</td>\n",
       "      <td>1.25</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>1</td>\n",
       "      <td>f</td>\n",
       "      <td>g</td>\n",
       "      <td>202.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a</td>\n",
       "      <td>58.67</td>\n",
       "      <td>4.460</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>q</td>\n",
       "      <td>h</td>\n",
       "      <td>3.04</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>6</td>\n",
       "      <td>f</td>\n",
       "      <td>g</td>\n",
       "      <td>43.0</td>\n",
       "      <td>560</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a</td>\n",
       "      <td>24.50</td>\n",
       "      <td>0.500</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>q</td>\n",
       "      <td>h</td>\n",
       "      <td>1.50</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>0</td>\n",
       "      <td>f</td>\n",
       "      <td>g</td>\n",
       "      <td>280.0</td>\n",
       "      <td>824</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b</td>\n",
       "      <td>27.83</td>\n",
       "      <td>1.540</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>w</td>\n",
       "      <td>v</td>\n",
       "      <td>3.75</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>5</td>\n",
       "      <td>t</td>\n",
       "      <td>g</td>\n",
       "      <td>100.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b</td>\n",
       "      <td>20.17</td>\n",
       "      <td>5.625</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>w</td>\n",
       "      <td>v</td>\n",
       "      <td>1.71</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>0</td>\n",
       "      <td>f</td>\n",
       "      <td>s</td>\n",
       "      <td>120.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  0      1      2  3  4  5  6     7  8  9   10 11 12     13   14 15\n",
       "0  b  30.83  0.000  u  g  w  v  1.25  t  t   1  f  g  202.0    0  1\n",
       "1  a  58.67  4.460  u  g  q  h  3.04  t  t   6  f  g   43.0  560  1\n",
       "2  a  24.50  0.500  u  g  q  h  1.50  t  f   0  f  g  280.0  824  1\n",
       "3  b  27.83  1.540  u  g  w  v  3.75  t  t   5  t  g  100.0    3  1\n",
       "4  b  20.17  5.625  u  g  w  v  1.71  t  f   0  f  s  120.0    0  1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Change the classes to 1 and 0\n",
    "credData.loc[credData[15] == '+', 15] = 1\n",
    "credData.loc[credData[15] == '-', 15] = 0\n",
    "credData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bizarre-islam",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     12\n",
       "1     12\n",
       "2      0\n",
       "3      6\n",
       "4      6\n",
       "5      9\n",
       "6      9\n",
       "7      0\n",
       "8      0\n",
       "9      0\n",
       "10     0\n",
       "11     0\n",
       "12     0\n",
       "13    13\n",
       "14     0\n",
       "15     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the number of null values in the dataset\n",
    "credData.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "searching-safety",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the dataset: (690, 16)\n",
      "Types of data in dataset: 0      object\n",
      "1     float64\n",
      "2     float64\n",
      "3      object\n",
      "4      object\n",
      "5      object\n",
      "6      object\n",
      "7     float64\n",
      "8      object\n",
      "9      object\n",
      "10      int64\n",
      "11     object\n",
      "12     object\n",
      "13    float64\n",
      "14      int64\n",
      "15     object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# print the shape and data types of each column\n",
    "print(f'Shape of the dataset: {credData.shape}')\n",
    "print(f'Types of data in dataset: {credData.dtypes}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "remarkable-madrid",
   "metadata": {},
   "source": [
    "There are few NA values, so we will drop them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "pretty-synthetic",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(653, 16)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove the rows with na values\n",
    "credData.dropna(inplace=True, axis=0)\n",
    "credData.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "modern-gnome",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     0\n",
       "1     0\n",
       "2     0\n",
       "3     0\n",
       "4     0\n",
       "5     0\n",
       "6     0\n",
       "7     0\n",
       "8     0\n",
       "9     0\n",
       "10    0\n",
       "11    0\n",
       "12    0\n",
       "13    0\n",
       "14    0\n",
       "15    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verify that no null values\n",
    "credData.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "velvet-exercise",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make dummy values from the categorical variables\n",
    "credCat = pd.get_dummies(credData[[0, 3, 4, 5, 6, 8, 9, 11, 12]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "respective-friendship",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate the numerical variables\n",
    "credNum = credData[[1, 2, 7, 10, 13, 14]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "municipal-factor",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the X and y variables\n",
    "X = pd.concat([credCat, credNum], axis=1)\n",
    "y = pd.Series(credData[15], dtype='int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "brave-period",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the dataset\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_trans = pd.DataFrame(scaler.fit_transform(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "signed-purpose",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into training and test sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_trans, y, test_size=0.3, random_state=123)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "southeast-albuquerque",
   "metadata": {},
   "source": [
    "# Ensemble Model Using the Averaging Technique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "rapid-yellow",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "tamil-istanbul",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the three base models\n",
    "model1 = LogisticRegression(random_state=123)\n",
    "model2 = KNeighborsClassifier(n_neighbors=5)\n",
    "model3 = RandomForestClassifier(n_estimators=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "guilty-assist",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(n_estimators=500)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit the models\n",
    "model1.fit(X_train, y_train)\n",
    "model2.fit(X_train, y_train)\n",
    "model3.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "limited-pursuit",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict the probabilities of each model\n",
    "pred1 = model1.predict_proba(X_test)\n",
    "pred2 = model2.predict_proba(X_test)\n",
    "pred3 = model3.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "referenced-mountain",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average the predictions generated from all of the three models\n",
    "ensemblepred = (pred1 + pred2 + pred3) / 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "foreign-retention",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.90183583, 0.09816417],\n",
       "       [0.95996145, 0.04003855],\n",
       "       [0.18757473, 0.81242527],\n",
       "       [0.05216821, 0.94783179]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the first four rows of the ensemble prediction\n",
    "ensemblepred[0:4, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ambient-acoustic",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n"
     ]
    }
   ],
   "source": [
    "# Print the order of each class from the prediction output\n",
    "print(model1.classes_)\n",
    "print(model2.classes_)\n",
    "print(model3.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "lesbian-projection",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0,\n",
       "       0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0,\n",
       "       1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0,\n",
       "       0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0,\n",
       "       0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1,\n",
       "       0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n",
       "       1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0,\n",
       "       1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the final predictions for each example\n",
    "pred = np.argmax(ensemblepred, axis=1)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "downtown-shepherd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[96 11]\n",
      " [ 8 81]]\n"
     ]
    }
   ],
   "source": [
    "# print the confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "print(confusion_matrix(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "robust-republican",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.90      0.91       107\n",
      "           1       0.88      0.91      0.90        89\n",
      "\n",
      "    accuracy                           0.90       196\n",
      "   macro avg       0.90      0.90      0.90       196\n",
      "weighted avg       0.90      0.90      0.90       196\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print classification report\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "greater-truth",
   "metadata": {},
   "source": [
    "# Ensemble Model Using the Weighted Averaging Technique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "aging-democrat",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take the weighted average of the predictions\n",
    "ensemblepred = (0.60 * pred1 + 0.20 * pred2 + 0.20 * pred3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "configured-canon",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.9209045 , 0.0790955 ],\n",
       "       [0.9471306 , 0.0528694 ],\n",
       "       [0.14563452, 0.85436548],\n",
       "       [0.08910278, 0.91089722]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the first four rows of the ensemble prediction array\n",
    "ensemblepred[0:4, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fifth-review",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0,\n",
       "       0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0,\n",
       "       1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0,\n",
       "       0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0,\n",
       "       0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1,\n",
       "       0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n",
       "       1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0,\n",
       "       1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate the final predictions from the probabilities\n",
    "pred = np.argmax(ensemblepred, axis=1)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "latest-secretariat",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[94 13]\n",
      " [ 8 81]]\n"
     ]
    }
   ],
   "source": [
    "# print the confusion matrix\n",
    "print(confusion_matrix(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "conscious-contrast",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.88      0.90       107\n",
      "           1       0.86      0.91      0.89        89\n",
      "\n",
      "    accuracy                           0.89       196\n",
      "   macro avg       0.89      0.89      0.89       196\n",
      "weighted avg       0.89      0.89      0.89       196\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print classification report\n",
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "owned-james",
   "metadata": {},
   "source": [
    "# Ensemble Model Using Max Voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "latin-laundry",
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct the ensemble model using the VotingClassifier() function\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "model1 = LogisticRegression(random_state=123)\n",
    "model2 = KNeighborsClassifier(n_neighbors=5)\n",
    "model3 = RandomForestClassifier(n_estimators=500)\n",
    "\n",
    "model = VotingClassifier(estimators=[('lr', model1), ('knn', model2), ('rf', model3)], voting='hard')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "incoming-trick",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('lr', LogisticRegression(random_state=123)),\n",
       "                             ('knn', KNeighborsClassifier()),\n",
       "                             ('rf', RandomForestClassifier(n_estimators=500))])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit the model\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "falling-pointer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set: 0.9030612244897959\n"
     ]
    }
   ],
   "source": [
    "# calculate accuracy\n",
    "print(f'Accuracy on test set: {model.score(X_test, y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "innovative-tunnel",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions\n",
    "pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "dress-dictionary",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[95 12]\n",
      " [ 7 82]]\n"
     ]
    }
   ],
   "source": [
    "# print confusion matrix\n",
    "print(confusion_matrix(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "settled-intersection",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.89      0.91       107\n",
      "           1       0.87      0.92      0.90        89\n",
      "\n",
      "    accuracy                           0.90       196\n",
      "   macro avg       0.90      0.90      0.90       196\n",
      "weighted avg       0.90      0.90      0.90       196\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print classification report\n",
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "protected-concentrate",
   "metadata": {},
   "source": [
    "# Ensemble Learning Using Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "running-singles",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the base learner\n",
    "bl1 = RandomForestClassifier(random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "shaped-armstrong",
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct the ensemble model\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "baggingLearner = BaggingClassifier(base_estimator=bl1,\n",
    "                                  n_estimators=10,\n",
    "                                  max_samples=0.8,\n",
    "                                  max_features=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "medical-legislation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the model\n",
    "model = baggingLearner.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "athletic-december",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions\n",
    "pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "gorgeous-cooking",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[94 13]\n",
      " [ 9 80]]\n"
     ]
    }
   ],
   "source": [
    "# confusion matrix\n",
    "print(confusion_matrix(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "textile-sterling",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.88      0.90       107\n",
      "           1       0.86      0.90      0.88        89\n",
      "\n",
      "    accuracy                           0.89       196\n",
      "   macro avg       0.89      0.89      0.89       196\n",
      "weighted avg       0.89      0.89      0.89       196\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# classification report\n",
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "underlying-industry",
   "metadata": {},
   "source": [
    "# Ensemble Learning Using Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "experimental-equivalent",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the base learner\n",
    "bl1 = LogisticRegression(random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "viral-bronze",
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct the ensemble model\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "boosting = AdaBoostClassifier(base_estimator=bl1, n_estimators=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "moved-poland",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the model\n",
    "model = boosting.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "connected-theology",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions\n",
    "pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "boxed-shade",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[96 11]\n",
      " [ 8 81]]\n"
     ]
    }
   ],
   "source": [
    "# confusion matrix\n",
    "print(confusion_matrix(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "offensive-gauge",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.90      0.91       107\n",
      "           1       0.88      0.91      0.90        89\n",
      "\n",
      "    accuracy                           0.90       196\n",
      "   macro avg       0.90      0.90      0.90       196\n",
      "weighted avg       0.90      0.90      0.90       196\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "together-substitute",
   "metadata": {},
   "source": [
    "# Ensemble Learning Using Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "utility-google",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create base learners\n",
    "bl1 = KNeighborsClassifier(n_neighbors=5)\n",
    "bl2 = RandomForestClassifier(random_state=123)\n",
    "ml = LogisticRegression(random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "vital-scientist",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create stacking classifier\n",
    "from mlxtend.classifier import StackingClassifier\n",
    "\n",
    "stackcl = StackingClassifier(classifiers=[bl1, bl2], meta_classifier=ml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "thermal-puzzle",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the model\n",
    "model = stackcl.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "median-crisis",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions\n",
    "pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "settled-formula",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[97 10]\n",
      " [ 9 80]]\n"
     ]
    }
   ],
   "source": [
    "# confusion matrix\n",
    "print(confusion_matrix(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "another-assessment",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.91      0.91       107\n",
      "           1       0.89      0.90      0.89        89\n",
      "\n",
      "    accuracy                           0.90       196\n",
      "   macro avg       0.90      0.90      0.90       196\n",
      "weighted avg       0.90      0.90      0.90       196\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# classification report\n",
    "print(classification_report(y_test, pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
