{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "announced-grace",
   "metadata": {},
   "source": [
    "# Preparing the Speed Dating Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sealed-chicken",
   "metadata": {},
   "source": [
    "<b> Download and load the dataset </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dated-envelope",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import package\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "straight-valuation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# url path\n",
    "url_path = 'https://raw.githubusercontent.com/PacktWorkshops/The-Data-Science-Workshop/master/Chapter11/dataset/Speed_Dating_Data.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "affected-samoa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iid</th>\n",
       "      <th>id</th>\n",
       "      <th>gender</th>\n",
       "      <th>idg</th>\n",
       "      <th>condtn</th>\n",
       "      <th>wave</th>\n",
       "      <th>round</th>\n",
       "      <th>position</th>\n",
       "      <th>positin1</th>\n",
       "      <th>order</th>\n",
       "      <th>...</th>\n",
       "      <th>attr3_3</th>\n",
       "      <th>sinc3_3</th>\n",
       "      <th>intel3_3</th>\n",
       "      <th>fun3_3</th>\n",
       "      <th>amb3_3</th>\n",
       "      <th>attr5_3</th>\n",
       "      <th>sinc5_3</th>\n",
       "      <th>intel5_3</th>\n",
       "      <th>fun5_3</th>\n",
       "      <th>amb5_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 195 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   iid   id  gender  idg  condtn  wave  round  position  positin1  order  ...  \\\n",
       "0    1  1.0       0    1       1     1     10         7       NaN      4  ...   \n",
       "1    1  1.0       0    1       1     1     10         7       NaN      3  ...   \n",
       "2    1  1.0       0    1       1     1     10         7       NaN     10  ...   \n",
       "3    1  1.0       0    1       1     1     10         7       NaN      5  ...   \n",
       "4    1  1.0       0    1       1     1     10         7       NaN      7  ...   \n",
       "\n",
       "   attr3_3  sinc3_3  intel3_3  fun3_3  amb3_3  attr5_3  sinc5_3  intel5_3  \\\n",
       "0      5.0      7.0       7.0     7.0     7.0      NaN      NaN       NaN   \n",
       "1      5.0      7.0       7.0     7.0     7.0      NaN      NaN       NaN   \n",
       "2      5.0      7.0       7.0     7.0     7.0      NaN      NaN       NaN   \n",
       "3      5.0      7.0       7.0     7.0     7.0      NaN      NaN       NaN   \n",
       "4      5.0      7.0       7.0     7.0     7.0      NaN      NaN       NaN   \n",
       "\n",
       "   fun5_3  amb5_3  \n",
       "0     NaN     NaN  \n",
       "1     NaN     NaN  \n",
       "2     NaN     NaN  \n",
       "3     NaN     NaN  \n",
       "4     NaN     NaN  \n",
       "\n",
       "[5 rows x 195 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(url_path)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "compound-bookmark",
   "metadata": {},
   "source": [
    "<b> Print out the dimensions of the DataFrame </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "amateur-upgrade",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8378, 195)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unique-dance",
   "metadata": {},
   "source": [
    "<b> Check for duplicate rows </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "short-skill",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "american-crowd",
   "metadata": {},
   "source": [
    "<b> Check for duplicate rows for the identifier columns (iid, id, partner, and pid) </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "blond-qatar",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['iid', 'id', 'partner', 'pid']].duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "going-uruguay",
   "metadata": {},
   "source": [
    "<b> Check for unexpected values for the following numerical variables: 'imprace', 'imprelig', 'sports', 'tvsports', 'exercise', 'dining', 'museums', 'art', 'hiking', 'gaming', 'clubbing', 'reading', 'tv', 'theater', 'movies', 'concerts', 'music', 'shopping', and 'yoga' </b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "desirable-buffalo",
   "metadata": {},
   "source": [
    "If you looked at the dataset description document, then you'll know that the values of the following variables should range between 1 and 10: 'imprace', 'imprelig', 'sports', 'tvsports', 'exercise', 'dining', 'museums', 'art', 'hiking', 'gaming', 'clubbing', 'reading', 'tv', 'theater', 'movies', 'concerts', 'music', 'shopping', 'yoga', 'exphappy', and 'satis_2'. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cutting-namibia",
   "metadata": {},
   "outputs": [],
   "source": [
    "# selecting columns of interest\n",
    "scale_1_10 = ['imprace', 'imprelig', 'sports', 'tvsports', 'exercise', 'dining', \\\n",
    "              'museums', 'art', 'hiking', 'gaming', 'clubbing', 'reading', 'tv', 'theater', \\\n",
    "              'movies', 'concerts', 'music', 'shopping', 'yoga', 'exphappy', 'satis_2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "serious-model",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a function to help de analysis\n",
    "def check_range(col, min_value, max_value):\n",
    "    return (col < min_value) | (col > max_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "magnetic-internship",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test your function on the 'imprace' column\n",
    "unexpected_mask = check_range(df['imprace'], 1, 10)\n",
    "unexpected_mask.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "swiss-circular",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a function to inspected all the dataframe\n",
    "def print_unexpected(df, col_name, unexp_mask):\n",
    "    if unexp_mask.sum() > 0:\n",
    "        print(col_name)\n",
    "        print(unexp_mask.sum())\n",
    "        print(df.loc[unexp_mask, col_name].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "handmade-france",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "imprace\n",
      "8\n",
      "[0.]\n"
     ]
    }
   ],
   "source": [
    "# Test your function on the 'imprace' column\n",
    "print_unexpected(df, 'imprace', unexpected_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "executive-attention",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function that takes a DataFrame, a list of columns, and min and max values as input parameters.\n",
    "# This function will iterate through each column from the given column list, call the check_range function,\n",
    "# and pass its output to the print_unexpected function\n",
    "\n",
    "def check_ranges(df, col_list, min_value, max_value):\n",
    "    for col_name in col_list:\n",
    "        unexpected_mask = check_range(df[col_name], min_value, max_value)\n",
    "        print_unexpected(df, col_name, unexpected_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "vocational-conversion",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "imprace\n",
      "8\n",
      "[0.]\n",
      "museums\n",
      "18\n",
      "[0.]\n",
      "art\n",
      "18\n",
      "[0.]\n",
      "hiking\n",
      "18\n",
      "[0.]\n",
      "gaming\n",
      "137\n",
      "[14.  0.]\n",
      "clubbing\n",
      "18\n",
      "[0.]\n",
      "reading\n",
      "51\n",
      "[13.]\n",
      "theater\n",
      "18\n",
      "[0.]\n",
      "movies\n",
      "18\n",
      "[0.]\n",
      "concerts\n",
      "18\n",
      "[0.]\n",
      "yoga\n",
      "36\n",
      "[0.]\n"
     ]
    }
   ],
   "source": [
    "# Test this function with the dataset and the scale_1_10 variables \n",
    "check_ranges(df, scale_1_10, 1, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bridal-memorabilia",
   "metadata": {},
   "source": [
    "<b> Replace the identified incorrect values </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "handled-surname",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a function to correct the dataframe\n",
    "def replace_value(df, col_name, incorrect_value, new_value):\n",
    "    df.loc[df[col_name] == incorrect_value, col_name] = new_value\n",
    "    print(col_name)\n",
    "    print(df[col_name].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "different-armstrong",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gaming\n",
      "[ 1.  5.  4.  6.  2.  3.  7.  8. 10. nan  9.  0.]\n"
     ]
    }
   ],
   "source": [
    "# using the function in the 'gaming' column\n",
    "replace_value(df, 'gaming', 14, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ranging-indianapolis",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading\n",
      "[ 6. 10.  7.  9.  8.  4.  5. nan  2.  3.  1.]\n"
     ]
    }
   ],
   "source": [
    "# using the function in the 'reading' column\n",
    "replace_value(df, 'reading', 13, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "qualified-snapshot",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a for loop that will iterate through the following suffixes:\n",
    "# ['1_1', '1_2', '1_3', '1_s', '2_1', '2_2', '2_3', '4_1', '4_2', '4_3', '7_2', and '7_3'].\n",
    "# For each of them, create a list comprehension so that you can extract the columns that contain\n",
    "# the given suffix and store them into a variable called suffix_cols.\n",
    "# Then, apply the check_ranges function to this list and use 0 and 100 as their minimum and maximum values\n",
    "\n",
    "for suffix in ['1_1', '1_2', '1_3', '1_s', '2_1', '2_2', '2_3', '4_1', '4_2', '4_3', '7_2', '7_3']:\n",
    "    suffix_cols = [col for col in df.columns if col.endswith(suffix)]\n",
    "    check_ranges(df, suffix_cols, 0, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "capable-display",
   "metadata": {},
   "source": [
    "No output is displayed, which means that all these columns have values within the expected range, that is, between 0 and 100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "annoying-museum",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attr3_3\n",
      "112\n",
      "[12.]\n",
      "sinc3_3\n",
      "173\n",
      "[12.]\n",
      "intel3_3\n",
      "233\n",
      "[12.]\n",
      "fun3_3\n",
      "153\n",
      "[12.]\n",
      "amb3_3\n",
      "147\n",
      "[12.]\n"
     ]
    }
   ],
   "source": [
    "# Create a for loop that's similar to the above for the suffixes ['3_1', '3_2', '3_3', '5_1', '5_2', '5_3', '3_s']\n",
    "# where 1 and 10 are the minimum and maximum values\n",
    "\n",
    "for suffix in ['3_1', '3_2', '3_3', '5_1', '5_2', '5_3', '3_s']:\n",
    "    suffix_cols = [col for col in df.columns if col.endswith(suffix)]\n",
    "    check_ranges(df, suffix_cols, 1, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "tribal-sword",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attr3_3\n",
      "[ 5.  7. nan  6.  4.  9.  8.  3. 10.  2.]\n",
      "sinc3_3\n",
      "[ 7.  6. nan  5.  8.  9. 10.  4.  3.  2.]\n",
      "intel3_3\n",
      "[ 7.  9. nan  6. 10.  8.  5.  4.  3.]\n",
      "fun3_3\n",
      "[ 7.  9. nan  8.  6.  3.  5. 10.  2.  4.]\n",
      "amb3_3\n",
      "[ 7.  4. nan  5. 10.  9.  8.  6.  2.  3.  1.]\n"
     ]
    }
   ],
   "source": [
    "# Create a for loop that iterates through the list of columns ending with 3_3 and call the replace_values\n",
    "for col in ['attr3_3', 'sinc3_3', 'intel3_3', 'fun3_3', 'amb3_3']:\n",
    "    replace_value(df, col, 12, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "metropolitan-blair",
   "metadata": {},
   "source": [
    "<b> Check the data type of the different columns </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "powered-fleet",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "iid           int64\n",
       "id          float64\n",
       "gender        int64\n",
       "idg           int64\n",
       "condtn        int64\n",
       "             ...   \n",
       "attr5_3     float64\n",
       "sinc5_3     float64\n",
       "intel5_3    float64\n",
       "fun5_3      float64\n",
       "amb5_3      float64\n",
       "Length: 195, dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dirty-highlight",
   "metadata": {},
   "source": [
    "<b> Change the data types to categorical for the columns that don't contain numerical values </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "hungarian-techno",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols = ['round', 'order', 'int_corr', 'age', 'mn_sat', 'income', 'expnum']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "spiritual-perry",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = df.columns.difference(num_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "public-northwest",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col_name in cat_cols:\n",
    "    df[col_name] = df[col_name].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "sensitive-scope",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "iid         category\n",
       "id          category\n",
       "gender      category\n",
       "idg         category\n",
       "condtn      category\n",
       "              ...   \n",
       "attr5_3     category\n",
       "sinc5_3     category\n",
       "intel5_3    category\n",
       "fun5_3      category\n",
       "amb5_3      category\n",
       "Length: 195, dtype: object"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "coupled-gilbert",
   "metadata": {},
   "source": [
    "<b> Check for any missing values for each numerical variable </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "floating-deviation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "round          0\n",
       "order          0\n",
       "int_corr     158\n",
       "age           95\n",
       "mn_sat      5245\n",
       "income      4099\n",
       "expnum      6578\n",
       "dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[num_cols].isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "governing-genius",
   "metadata": {},
   "source": [
    "<b> Replace the missing values for each numerical variable with their corresponding mean or median values </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "successful-trail",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.14,  0.54,  0.16,  0.61,  0.21,  0.25,  0.34,  0.5 ,  0.28,\n",
       "       -0.36,  0.29,  0.18,  0.1 , -0.21,  0.32,  0.73,  0.6 ,  0.07,\n",
       "        0.11,  0.39, -0.24, -0.14,  0.09, -0.04, -0.3 , -0.26, -0.15,\n",
       "       -0.47, -0.18,  0.05,  0.37,  0.35,  0.15, -0.19, -0.43,  0.  ,\n",
       "       -0.17,  0.08, -0.16,  0.06, -0.05, -0.13, -0.06,  0.33, -0.51,\n",
       "        0.12,  0.19,  0.47,  0.03,  0.46,  0.43,  0.52, -0.46, -0.27,\n",
       "        0.59,  0.31, -0.34, -0.03, -0.11,  0.42, -0.4 , -0.23,  0.17,\n",
       "        0.68, -0.01, -0.35,  0.3 ,  0.65,  0.24,  0.41,  0.49,  0.01,\n",
       "        0.22, -0.08,  0.27,  0.44,  0.62, -0.2 , -0.02, -0.33, -0.52,\n",
       "       -0.1 ,  0.58, -0.57, -0.31, -0.07, -0.32,  0.04, -0.12,  0.48,\n",
       "       -0.22, -0.29,  0.38,  0.53, -0.38,  0.02, -0.28,  0.13,  0.2 ,\n",
       "         nan, -0.41, -0.44,  0.51, -0.48,  0.4 ,  0.26,  0.77, -0.49,\n",
       "       -0.25, -0.09,  0.45, -0.39,  0.83,  0.57, -0.61,  0.72, -0.37,\n",
       "        0.23, -0.58,  0.8 , -0.56,  0.63, -0.63,  0.71,  0.36,  0.56,\n",
       "        0.55,  0.76,  0.69,  0.79,  0.9 ,  0.67,  0.66,  0.81,  0.64,\n",
       "        0.74,  0.75,  0.85, -0.42, -0.5 , -0.59,  0.7 ,  0.82,  0.78,\n",
       "       -0.45, -0.83,  0.88, -0.7 , -0.62, -0.55,  0.87,  0.91,  0.84,\n",
       "       -0.64, -0.73, -0.54])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['int_corr'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "religious-inspection",
   "metadata": {},
   "source": [
    "The values of the int_corr column range between -1 and 1. It seems like they have been normalized. Since there are no extreme values or outliers, you can impute the missing values with the mean of this variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "binary-doctrine",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "158"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int_corr_mask = df['int_corr'].isna()\n",
    "int_corr_mask.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "opening-antigua",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.19600973236009664"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int_corr_mean = df['int_corr'].mean()\n",
    "int_corr_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "convinced-house",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['int_corr'].fillna(int_corr_mean, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "strange-typing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['int_corr'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "approximate-richardson",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_num_cols = ['age', 'mn_sat', 'income', 'expnum']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "black-script",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age\n",
      "[21. 24. 25. 23. 22. 26. 27. 30. 28. nan 29. 34. 35. 32. 39. 20. 19. 18.\n",
      " 37. 33. 36. 31. 42. 38. 55.]\n",
      "mn_sat\n",
      "[  nan 1070. 1258. 1400. 1290. 1460. 1430. 1215. 1330. 1450. 1155. 1140.\n",
      " 1360. 1402. 1250. 1210. 1220. 1410. 1260. 1380. 1030. 1309. 1308. 1050.\n",
      " 1100. 1310. 1490. 1188. 1097. 1212. 1340. 1034. 1185. 1242. 1160. 1099.\n",
      " 1214. 1270. 1110. 1178. 1060. 1157. 1180. 1014. 1341.  990. 1320. 1159.\n",
      " 1370. 1105. 1365. 1011. 1130. 1206. 1331. 1191.  914. 1200. 1080. 1090.\n",
      " 1092. 1470. 1149. 1134. 1230. 1267. 1280. 1227. 1239.]\n",
      "income\n",
      "[ 69487.  65929.     nan  37754.  86340.  60304.  54620.  48652.  29237.\n",
      "  56580.  36782.  38548.  52010.  28418.  43185.  23152.  43664.  48441.\n",
      "  61152.  36485.  41507.  17134.  30038.  33772.  24997.  42096.  28891.\n",
      "  62635.  12063.  29809.  26482.  30147.  39919.  41466.  23988.  28989.\n",
      "  50948.  38022.  47559.  53539.  32159.  53940.  40753.  38207.  46166.\n",
      "  30973.  28317.  26645.  25589.  55223. 109031.  40409.  21597.  76624.\n",
      "  35968.  51725.  55419.  55550.  26682.  41547.  23361.  74893.  52804.\n",
      "  53923.  27094.  57213.  42390.  43636.  57887.  30768.  66699.  45360.\n",
      "  55080.  17378.  40375.  48929.  78193.  63351.  50745.  29279.  38774.\n",
      "  58802.  41831.  52186.  97857.  74624.  21590.  38832.  37248.  28240.\n",
      "  53771.  56096.  31560.  52467.  80006.  47572.  22439.  31383.  40749.\n",
      "  47997.  78704.  31143.  32129.  44195.  46837.  97972.  35960.  65708.\n",
      "  49466.  53229.  32649.  35867.  40244.  42640.  52388.  62875.  30855.\n",
      "  46800.  45695.  46792.  53501.  64716.  27248.  22805.  56118.  30146.\n",
      "  39123.  46153.  45300.  42397.  44346.  42225.  37405.  28524.  61141.\n",
      "   8607.  41476.  49841.  37240.  36594.  62997.  46608.  37881.  48944.\n",
      "  77112.  18283.  31432.  73073.  26706.  50060.  25401.  80608.  43844.\n",
      "  53196.  25786.  39394.  40695.  45788.  37315.  51663.  32563.  54303.\n",
      "  16908.  39729.  57316.  30587.  57513.  31857.  23207.  25831.  28759.\n",
      "  19264.  41778.  35963.  49409.  31516.  36223.  43367.  27503.  35187.\n",
      "  26298.  31148.  55704.  46138.  66827.  42897.  31809.  75347.  47005.\n",
      "  52805.  50725.  65693.  45736.  33906.  50501.  48785.  52318.  62844.\n",
      "  52586.  29236.  31486.  31632. 106663.  84043.  35224.  36381.  65498.\n",
      "  60000.  22669.  81266.  29746.  47556.  42651.  27794.  41737.  90225.\n",
      "  52280.  56056.  60835.  62829.  16767.  42967.  21488.  89977.  18619.\n",
      "  22161.  82734.  40163.  46185.  78844.  29575.  34752.  22173.  37994.\n",
      "  35409.  23707.  57501.  25314.  48876.  34870.  35848.  45017.  12416.\n",
      "  87789.  50572.  49642.  20000.  32508.  35627.  46280.  41191.  71787.\n",
      "  72412.  36510.  32386.  15863.  46272.  48137.  61686.  47624.  36673.\n",
      "  55138.]\n",
      "expnum\n",
      "[ 2.  5. 10.  3. 15. 20.  4.  9. 19.  0. nan  8. 12.  1.  7.  6. 18. 14.\n",
      " 13.]\n"
     ]
    }
   ],
   "source": [
    "for col_name in missing_num_cols:\n",
    "    print(col_name)\n",
    "    print(df[col_name].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "brazilian-dover",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age\n",
      "26.0\n",
      "mn_sat\n",
      "1310.0\n",
      "income\n",
      "43185.0\n",
      "expnum\n",
      "4.0\n"
     ]
    }
   ],
   "source": [
    "for col_name in missing_num_cols:\n",
    "    col_median = df[col_name].median()\n",
    "    df[col_name].fillna(col_median, inplace=True)\n",
    "    print(col_name)\n",
    "    print(col_median)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "round-flour",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age       0\n",
       "mn_sat    0\n",
       "income    0\n",
       "expnum    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[missing_num_cols].isna().sum()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
